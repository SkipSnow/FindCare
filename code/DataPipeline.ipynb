{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h1><strong>1. Project overview</strong></h1>\n",
        "<ol type=\"a\">\n",
        "  <li>Documentation is found in the Project documentation folder.</li>\n",
        "  <li>This note-book is the data pipeline that enriches the provider collection in the Mongo db. repository </li>\n",
        "</ol>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<hr style=\"border: none; height: 2px; background-color: blue; margin-top: 6px; margin-bottom: 0;\" />\n",
        "<small>Add all imports and get the DB</small>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "# --- Standard library ---\n",
        "import csv\n",
        "import math\n",
        "import os\n",
        "import re\n",
        "from dataclasses import asdict, dataclass, field\n",
        "from decimal import Decimal, ROUND_HALF_UP\n",
        "from pathlib import Path\n",
        "from typing import Any, Dict, Iterable, List, Optional, Tuple\n",
        "\n",
        "# --- Third-party ---\n",
        "import pandas as pd\n",
        "from bson.decimal128 import Decimal128\n",
        "from dotenv import load_dotenv\n",
        "from pymongo import MongoClient\n",
        "from pymongo.collection import Collection\n",
        "\n",
        "# --- Local / project ---\n",
        "from Utilities.ChatHealthyMongoUtilities import ChatHealthyMongoUtilities\n",
        "\n",
        "\n",
        "load_dotenv()  # <-- REQUIRED for .env files\n",
        "\n",
        "conn_str = os.getenv(\"MONGO_connectionString\")\n",
        "if not conn_str:\n",
        "    raise EnvironmentError(\"MONGO_connectionString is not set\")\n",
        "\n",
        "DbUtil = ChatHealthyMongoUtilities(conn_str)\n",
        "DB = DbUtil.getConnection()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from IPython.display import HTML, display\n",
        "\n",
        "# Wrap long output text in notebook cells\n",
        "\n",
        "display(HTML(\"\"\"\n",
        "<style>\n",
        ".output_area pre {\n",
        "    white-space: pre-wrap !important;\n",
        "    word-break: break-word !important;\n",
        "}\n",
        "</style>\n",
        "\"\"\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Get zip -to county csv and load it to the db but also get the FIPS county name file so the file can be enriched with the county name cross walk. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "# -----------------------------\n",
        "# Results\n",
        "# -----------------------------\n",
        "@dataclass(frozen=True)\n",
        "class LoadResults:\n",
        "    # HUD source (rows from ZIP_COUNTY_*.csv)\n",
        "    hud_rows_read: int\n",
        "    hud_rows_skipped_missing_required: int  # missing ZIP/COUNTY/TOT_RATIO after parsing\n",
        "    hud_rows_skipped_non_county_fips: int   # COUNTY not present in county-level FIPS map (Summary Level != 050)\n",
        "    hud_rows_considered_for_normalization: int  # rows that passed validation and county-only filter\n",
        "    hud_rows_written: int                  # number of normalized ZIP docs written (unique ZIPs)\n",
        "\n",
        "    # County lookup source (Census all-geocodes)\n",
        "    county_lookup_rows_read: int\n",
        "    county_lookup_rows_written: int\n",
        "    county_lookup_counties_in_map: int     # how many county FIPS were captured (Summary Level 050)\n",
        "\n",
        "    # Raw HUD crosswalk (loaded AS-IS)\n",
        "    census_crosswalk_rows_read: int\n",
        "    census_crosswalk_rows_written: int\n",
        "\n",
        "    # Enrichment metric\n",
        "    normalized_zips_missing_county_name: int  # should be 0 when county-only filter is enforced\n",
        "\n",
        "    # Validation metrics\n",
        "    raw_hud_distinct_zips: int\n",
        "    normalized_distinct_zips: int\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Helpers\n",
        "# -----------------------------\n",
        "def _is_collection_empty(col: Collection) -> bool:\n",
        "    return col.estimated_document_count() == 0\n",
        "\n",
        "\n",
        "def _s(v: Any) -> Optional[str]:\n",
        "    if v is None:\n",
        "        return None\n",
        "    s = str(v).strip()\n",
        "    return s if s != \"\" else None\n",
        "\n",
        "\n",
        "def _zip5(value: Any) -> Optional[str]:\n",
        "    if value is None:\n",
        "        return None\n",
        "    s = str(value).strip()\n",
        "    if s == \"\":\n",
        "        return None\n",
        "    digits = \"\".join(ch for ch in s if ch.isdigit())\n",
        "    if len(digits) == 0:\n",
        "        return None\n",
        "    if len(digits) > 5:\n",
        "        digits = digits[:5]\n",
        "    return digits.zfill(5)\n",
        "\n",
        "\n",
        "def _to_decimal128(value: Any) -> Optional[Decimal128]:\n",
        "    \"\"\"\n",
        "    Convert a numeric-looking value into BSON Decimal128.\n",
        "    Returns None if the value is blank/unparseable.\n",
        "    \"\"\"\n",
        "    if value is None:\n",
        "        return None\n",
        "    s = str(value).strip()\n",
        "    if s == \"\":\n",
        "        return None\n",
        "    try:\n",
        "        return Decimal128(Decimal(s))\n",
        "    except (InvalidOperation, ValueError):\n",
        "        return None\n",
        "\n",
        "\n",
        "def _read_csv_rows(path: str) -> Tuple[List[str], List[Dict[str, Any]]]:\n",
        "    with open(path, \"r\", newline=\"\", encoding=\"utf-8-sig\") as f:\n",
        "        reader = csv.DictReader(f)\n",
        "        if not reader.fieldnames:\n",
        "            raise ValueError(f\"No header row found in CSV: {path}\")\n",
        "        headers = list(reader.fieldnames)\n",
        "        rows = [r for r in reader]\n",
        "        return headers, rows\n",
        "\n",
        "\n",
        "def _read_xlsx_rows(path: str) -> Tuple[List[str], List[Dict[str, Any]]]:\n",
        "    from openpyxl import load_workbook  # type: ignore\n",
        "\n",
        "    wb = load_workbook(path, read_only=True, data_only=True)\n",
        "    ws = wb.active\n",
        "\n",
        "    rows_iter = ws.iter_rows(values_only=True)\n",
        "    try:\n",
        "        header_row = next(rows_iter)\n",
        "    except StopIteration:\n",
        "        raise ValueError(f\"Empty XLSX: {path}\")\n",
        "\n",
        "    headers = [str(h).strip() if h is not None else \"\" for h in header_row]\n",
        "    if not any(headers):\n",
        "        raise ValueError(f\"Header row appears empty in XLSX: {path}\")\n",
        "\n",
        "    out: List[Dict[str, Any]] = []\n",
        "    for row in rows_iter:\n",
        "        doc: Dict[str, Any] = {}\n",
        "        for i, h in enumerate(headers):\n",
        "            if h == \"\":\n",
        "                continue\n",
        "            doc[h] = row[i] if i < len(row) else None\n",
        "        if any(v is not None and str(v).strip() != \"\" for v in doc.values()):\n",
        "            out.append(doc)\n",
        "\n",
        "    return headers, out\n",
        "\n",
        "\n",
        "def _read_tabular_rows(path: str) -> Tuple[List[str], List[Dict[str, Any]]]:\n",
        "    ext = os.path.splitext(path.lower())[1]\n",
        "    if ext in [\".csv\", \".txt\"]:\n",
        "        return _read_csv_rows(path)\n",
        "    if ext in [\".xlsx\", \".xlsm\"]:\n",
        "        return _read_xlsx_rows(path)\n",
        "    raise ValueError(f\"Unsupported file type '{ext}'. Use .csv or .xlsx/.xlsm: {path}\")\n",
        "\n",
        "\n",
        "def _insert_many_in_batches(\n",
        "    col: Collection,\n",
        "    docs: List[Dict[str, Any]],\n",
        "    batch_size: int = 1000,\n",
        ") -> int:\n",
        "    if not docs:\n",
        "        return 0\n",
        "    total = 0\n",
        "    for i in range(0, len(docs), batch_size):\n",
        "        chunk = docs[i : i + batch_size]\n",
        "        col.insert_many(chunk, ordered=False)\n",
        "        total += len(chunk)\n",
        "    return total\n",
        "\n",
        "\n",
        "def _normalize_key(s: str) -> str:\n",
        "    return \"\".join(ch.lower() for ch in s if ch.isalnum())\n",
        "\n",
        "\n",
        "def _find_col(headers: List[str], candidates: List[str]) -> Optional[str]:\n",
        "    norm_map = {_normalize_key(h): h for h in headers if h is not None}\n",
        "    for c in candidates:\n",
        "        key = _normalize_key(c)\n",
        "        if key in norm_map:\n",
        "            return norm_map[key]\n",
        "    return None\n",
        "\n",
        "\n",
        "def _build_fips_to_county_name_map_from_rows(\n",
        "    headers: List[str],\n",
        "    rows: List[Dict[str, Any]],\n",
        ") -> Dict[str, str]:\n",
        "    \"\"\"\n",
        "    Builds map: 5-digit county FIPS -> county name.\n",
        "\n",
        "    Supports your \"all-geocodes-v2021.csv\" format:\n",
        "      - Summary Level\n",
        "      - State Code (FIPS)\n",
        "      - County Code (FIPS)\n",
        "      - Area Name (including legal/statistical area description)\n",
        "\n",
        "    County rows use Summary Level == '050'.\n",
        "    countyFips = zfill2(State Code) + zfill3(County Code)\n",
        "\n",
        "    Also includes fallback logic for other Census schemas.\n",
        "    \"\"\"\n",
        "    summary_col = _find_col(headers, [\"Summary Level\"])\n",
        "    state_code_col = _find_col(headers, [\"State Code (FIPS)\"])\n",
        "    county_code_col = _find_col(headers, [\"County Code (FIPS)\"])\n",
        "    area_name_col = _find_col(headers, [\"Area Name (including legal/statistical area description)\"])\n",
        "\n",
        "    is_all_geocodes = all([summary_col, state_code_col, county_code_col, area_name_col])\n",
        "\n",
        "    out: Dict[str, str] = {}\n",
        "\n",
        "    if is_all_geocodes:\n",
        "        for row in rows:\n",
        "            summary = str(row.get(summary_col, \"\")).strip()\n",
        "            if summary != \"050\":\n",
        "                continue\n",
        "\n",
        "            st_raw = row.get(state_code_col)\n",
        "            co_raw = row.get(county_code_col)\n",
        "            nm_raw = row.get(area_name_col)\n",
        "\n",
        "            st = \"\".join(ch for ch in str(st_raw).strip() if ch.isdigit()) if st_raw is not None else \"\"\n",
        "            co = \"\".join(ch for ch in str(co_raw).strip() if ch.isdigit()) if co_raw is not None else \"\"\n",
        "            name = str(nm_raw).strip() if nm_raw is not None else \"\"\n",
        "\n",
        "            if st == \"\" or co == \"\" or name == \"\":\n",
        "                continue\n",
        "\n",
        "            county_fips = st.zfill(2) + co.zfill(3)\n",
        "            out.setdefault(county_fips, name)\n",
        "\n",
        "        if not out:\n",
        "            raise ValueError(\n",
        "                \"Detected an all-geocodes style file, but found zero county rows (Summary Level '050'). \"\n",
        "                \"Inspect the 'Summary Level' column and tell me the value used for counties if it differs.\"\n",
        "            )\n",
        "        return out\n",
        "\n",
        "    # Fallback generic schema\n",
        "    statefp_col = _find_col(headers, [\"STATEFP\", \"STATEFP20\", \"STATEFP10\", \"StateFP\"])\n",
        "    countyfp_col = _find_col(headers, [\"COUNTYFP\", \"COUNTYFP20\", \"COUNTYFP10\", \"CountyFP\"])\n",
        "    fips_col = _find_col(headers, [\"FIPS\", \"GEOID\", \"COUNTYFIPS\", \"COUNTY_FIPS\", \"COUNTYFP\"])\n",
        "    name_col = _find_col(headers, [\"COUNTYNAME\", \"COUNTY_NAME\", \"NAMELSAD\", \"NAME\"])\n",
        "\n",
        "    if name_col is None:\n",
        "        raise ValueError(\n",
        "            \"Could not find a county name column in the county lookup file. \"\n",
        "            f\"Headers seen: {headers}\"\n",
        "        )\n",
        "\n",
        "    for row in rows:\n",
        "        nm_raw = row.get(name_col)\n",
        "        county_name = str(nm_raw).strip() if nm_raw is not None else \"\"\n",
        "        if county_name == \"\":\n",
        "            continue\n",
        "\n",
        "        fips: Optional[str] = None\n",
        "\n",
        "        if statefp_col and countyfp_col:\n",
        "            st = row.get(statefp_col)\n",
        "            co = row.get(countyfp_col)\n",
        "            if st is not None and co is not None:\n",
        "                st_s = \"\".join(ch for ch in str(st) if ch.isdigit()).zfill(2)\n",
        "                co_s = \"\".join(ch for ch in str(co) if ch.isdigit()).zfill(3)\n",
        "                if len(st_s) == 2 and len(co_s) == 3:\n",
        "                    fips = st_s + co_s\n",
        "\n",
        "        if fips is None and fips_col:\n",
        "            v = row.get(fips_col)\n",
        "            if v is not None:\n",
        "                digits = \"\".join(ch for ch in str(v) if ch.isdigit())\n",
        "                if len(digits) >= 5:\n",
        "                    fips = digits[-5:]\n",
        "\n",
        "        if fips:\n",
        "            out.setdefault(fips, county_name)\n",
        "\n",
        "    if not out:\n",
        "        raise ValueError(\n",
        "            \"Built an empty county FIPS -> county name map. Headers may not match expected patterns.\"\n",
        "        )\n",
        "\n",
        "    return out\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Main loader\n",
        "# -----------------------------\n",
        "def load_county_zip_with_census_collections(\n",
        "    argDbConnection: MongoClient,\n",
        "    argDatabaseName: str,\n",
        "\n",
        "    # 2 source files\n",
        "    argHudCountyZipCsvPath: str,\n",
        "    argCountyFipsNameFilePath: str,\n",
        "\n",
        "    # 3 collections\n",
        "    argHudNormalizedCollectionName: str,\n",
        "    argCountyLookupCollectionName: str,\n",
        "    argCensusCrosswalkCollectionName: str,\n",
        "\n",
        "    argBatchSize: int = 1000,\n",
        ") -> LoadResults:\n",
        "    \"\"\"\n",
        "    Creates/loads THREE collections, using TWO source files:\n",
        "\n",
        "    Source file #1: argHudCountyZipCsvPath (HUD ZIP-County crosswalk CSV)\n",
        "      - Loaded AS-IS into argCensusCrosswalkCollectionName\n",
        "      - Also normalized into argHudNormalizedCollectionName (highest TOT_RATIO per ZIP)\n",
        "      - Normalized collection is restricted to COUNTY FIPS that exist in the county-only\n",
        "        lookup map (Summary Level 050).\n",
        "\n",
        "    Source file #2: argCountyFipsNameFilePath (County FIPS -> County Name reference)\n",
        "      - Loaded AS-IS into argCountyLookupCollectionName\n",
        "      - Used to enrich normalized records with countyName\n",
        "      - Supports Census \"all-geocodes\" CSV format\n",
        "\n",
        "    Normalized fields written:\n",
        "      ZIP                 -> zip (ZIP5 string)\n",
        "      COUNTY              -> countyFips (5-digit string)\n",
        "      (derived)           -> countyName (string, from Summary Level 050 rows only)\n",
        "      USPS_ZIP_PREF_CITY  -> mainCity\n",
        "      USPS_ZIP_PREF_STATE -> state\n",
        "      TOT_RATIO           -> percentOfZipInCounty (BSON Decimal128)\n",
        "\n",
        "    Loads each collection only if empty, and returns a detailed validation report.\n",
        "    \"\"\"\n",
        "    db = argDbConnection[argDatabaseName]\n",
        "\n",
        "    normalized_col = db[argHudNormalizedCollectionName]\n",
        "    county_lookup_col = db[argCountyLookupCollectionName]\n",
        "    census_crosswalk_col = db[argCensusCrosswalkCollectionName]\n",
        "\n",
        "    # Read HUD crosswalk once\n",
        "    hud_headers, hud_rows = _read_csv_rows(argHudCountyZipCsvPath)\n",
        "\n",
        "    required = [\"ZIP\", \"COUNTY\", \"USPS_ZIP_PREF_CITY\", \"USPS_ZIP_PREF_STATE\", \"TOT_RATIO\"]\n",
        "    missing = [h for h in required if h not in hud_headers]\n",
        "    if missing:\n",
        "        raise ValueError(\n",
        "            \"HUD CSV is missing required columns: \"\n",
        "            f\"{missing}. Headers seen: {hud_headers}\"\n",
        "        )\n",
        "\n",
        "    # Compute raw distinct zips in HUD (for validation)\n",
        "    raw_zip_set = set()\n",
        "    for row in hud_rows:\n",
        "        z = _zip5(row.get(\"ZIP\"))\n",
        "        if z:\n",
        "            raw_zip_set.add(z)\n",
        "    raw_hud_distinct_zips = len(raw_zip_set)\n",
        "\n",
        "    # 1) Load HUD crosswalk AS-IS into raw collection\n",
        "    census_crosswalk_rows_read = len(hud_rows)\n",
        "    census_crosswalk_rows_written = 0\n",
        "    if _is_collection_empty(census_crosswalk_col):\n",
        "        census_crosswalk_rows_written = _insert_many_in_batches(\n",
        "            census_crosswalk_col, hud_rows, batch_size=argBatchSize\n",
        "        )\n",
        "\n",
        "    # 2) Load county lookup AS-IS into lookup collection\n",
        "    county_headers, county_rows = _read_tabular_rows(argCountyFipsNameFilePath)\n",
        "\n",
        "    county_lookup_rows_read = len(county_rows)\n",
        "    county_lookup_rows_written = 0\n",
        "    if _is_collection_empty(county_lookup_col):\n",
        "        county_lookup_rows_written = _insert_many_in_batches(\n",
        "            county_lookup_col, county_rows, batch_size=argBatchSize\n",
        "        )\n",
        "\n",
        "    # Build county-only map (Summary Level 050)\n",
        "    fips_to_name = _build_fips_to_county_name_map_from_rows(county_headers, county_rows)\n",
        "    county_lookup_counties_in_map = len(fips_to_name)\n",
        "\n",
        "    # 3) Normalize HUD + enrich with countyName; enforce county-only via fips_to_name membership\n",
        "    hud_rows_read = 0\n",
        "    hud_rows_skipped_missing_required = 0\n",
        "    hud_rows_skipped_non_county_fips = 0\n",
        "    hud_rows_considered_for_normalization = 0\n",
        "\n",
        "    hud_rows_written = 0\n",
        "    normalized_zips_missing_county_name = 0\n",
        "\n",
        "    if _is_collection_empty(normalized_col):\n",
        "        best_by_zip: Dict[str, Dict[str, Any]] = {}\n",
        "\n",
        "        for row in hud_rows:\n",
        "            hud_rows_read += 1\n",
        "\n",
        "            zip5 = _zip5(row.get(\"ZIP\"))\n",
        "            county_digits = \"\".join(ch for ch in str(row.get(\"COUNTY\", \"\")).strip() if ch.isdigit())\n",
        "            county_fips = county_digits.zfill(5) if county_digits else None\n",
        "            ratio128 = _to_decimal128(row.get(\"TOT_RATIO\"))\n",
        "\n",
        "            if zip5 is None or county_fips is None or ratio128 is None:\n",
        "                hud_rows_skipped_missing_required += 1\n",
        "                continue\n",
        "\n",
        "            # COUNTY-ONLY FILTER: Only accept counties present in the 050-only map\n",
        "            county_name = fips_to_name.get(county_fips)\n",
        "            if county_name is None:\n",
        "                hud_rows_skipped_non_county_fips += 1\n",
        "                continue\n",
        "\n",
        "            hud_rows_considered_for_normalization += 1\n",
        "\n",
        "            candidate = {\n",
        "                \"zip\": zip5,\n",
        "                \"countyFips\": county_fips,\n",
        "                \"countyName\": county_name,  # should always be present due to filter\n",
        "                \"mainCity\": _s(row.get(\"USPS_ZIP_PREF_CITY\")),\n",
        "                \"state\": _s(row.get(\"USPS_ZIP_PREF_STATE\")),\n",
        "                \"percentOfZipInCounty\": ratio128,  # Decimal128\n",
        "            }\n",
        "\n",
        "            current = best_by_zip.get(zip5)\n",
        "            if current is None:\n",
        "                best_by_zip[zip5] = candidate\n",
        "            else:\n",
        "                cur_val = current[\"percentOfZipInCounty\"].to_decimal()\n",
        "                new_val = ratio128.to_decimal()\n",
        "                if new_val > cur_val:\n",
        "                    best_by_zip[zip5] = candidate\n",
        "\n",
        "        docs = list(best_by_zip.values())\n",
        "\n",
        "        # Should be zero now, but keep metric anyway\n",
        "        normalized_zips_missing_county_name = sum(1 for d in docs if not d.get(\"countyName\"))\n",
        "\n",
        "        hud_rows_written = _insert_many_in_batches(\n",
        "            normalized_col, docs, batch_size=argBatchSize\n",
        "        )\n",
        "\n",
        "        # Helpful indexes for your common queries\n",
        "        normalized_col.create_index(\"zip\")\n",
        "        normalized_col.create_index([(\"zip\", 1), (\"countyFips\", 1)])\n",
        "        county_lookup_col.create_index(\"Summary Level\")\n",
        "        county_lookup_col.create_index(\"State Code (FIPS)\")\n",
        "        county_lookup_col.create_index(\"County Code (FIPS)\")\n",
        "        census_crosswalk_col.create_index(\"ZIP\")\n",
        "        census_crosswalk_col.create_index(\"COUNTY\")\n",
        "\n",
        "    else:\n",
        "        # If collection already exists, we still return validation stats from sources,\n",
        "        # but we will not rewrite normalized data.\n",
        "        hud_rows_read = len(hud_rows)\n",
        "        # We won't recompute these without reading DB; leave them as 0 to avoid false claims.\n",
        "        hud_rows_skipped_missing_required = 0\n",
        "        hud_rows_skipped_non_county_fips = 0\n",
        "        hud_rows_considered_for_normalization = 0\n",
        "        hud_rows_written = 0\n",
        "        normalized_zips_missing_county_name = 0\n",
        "\n",
        "    # Validation: distinct zips in normalized collection\n",
        "    normalized_distinct_zips = normalized_col.distinct(\"zip\")\n",
        "    normalized_distinct_zips_count = len(normalized_distinct_zips)\n",
        "\n",
        "    return LoadResults(\n",
        "        hud_rows_read=hud_rows_read,\n",
        "        hud_rows_skipped_missing_required=hud_rows_skipped_missing_required,\n",
        "        hud_rows_skipped_non_county_fips=hud_rows_skipped_non_county_fips,\n",
        "        hud_rows_considered_for_normalization=hud_rows_considered_for_normalization,\n",
        "        hud_rows_written=hud_rows_written,\n",
        "        county_lookup_rows_read=county_lookup_rows_read,\n",
        "        county_lookup_rows_written=county_lookup_rows_written,\n",
        "        county_lookup_counties_in_map=county_lookup_counties_in_map,\n",
        "        census_crosswalk_rows_read=census_crosswalk_rows_read,\n",
        "        census_crosswalk_rows_written=census_crosswalk_rows_written,\n",
        "        normalized_zips_missing_county_name=normalized_zips_missing_county_name,\n",
        "        raw_hud_distinct_zips=raw_hud_distinct_zips,\n",
        "        normalized_distinct_zips=normalized_distinct_zips_count,\n",
        "    )\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Enrich countyzip with GDP data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# File: EnrichCountyZipWithCountyGDPData.ipynb (single cell)\n",
        "# Author: Skip Snow\n",
        "# Co-Author: GPT-5\n",
        "# Copyright (c) 2025 Skip Snow. All rights reserved.\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "# -----------------------------\n",
        "# Imports\n",
        "# -----------------------------\n",
        "import re\n",
        "from dataclasses import dataclass\n",
        "from typing import Any, Dict, List, Optional, Tuple\n",
        "\n",
        "import pandas as pd\n",
        "from pymongo import MongoClient\n",
        "from pymongo.collection import Collection\n",
        "\n",
        "# -----------------------------\n",
        "# Constants\n",
        "# -----------------------------\n",
        "_US_STATE_ABBR_TO_NAME: Dict[str, str] = {\n",
        "    \"AL\": \"Alabama\",\"AK\": \"Alaska\",\"AZ\": \"Arizona\",\"AR\": \"Arkansas\",\"CA\": \"California\",\n",
        "    \"CO\": \"Colorado\",\"CT\": \"Connecticut\",\"DE\": \"Delaware\",\"DC\": \"District of Columbia\",\n",
        "    \"FL\": \"Florida\",\"GA\": \"Georgia\",\"HI\": \"Hawaii\",\"ID\": \"Idaho\",\"IL\": \"Illinois\",\n",
        "    \"IN\": \"Indiana\",\"IA\": \"Iowa\",\"KS\": \"Kansas\",\"KY\": \"Kentucky\",\"LA\": \"Louisiana\",\n",
        "    \"ME\": \"Maine\",\"MD\": \"Maryland\",\"MA\": \"Massachusetts\",\"MI\": \"Michigan\",\"MN\": \"Minnesota\",\n",
        "    \"MS\": \"Mississippi\",\"MO\": \"Missouri\",\"MT\": \"Montana\",\"NE\": \"Nebraska\",\"NV\": \"Nevada\",\n",
        "    \"NH\": \"New Hampshire\",\"NJ\": \"New Jersey\",\"NM\": \"New Mexico\",\"NY\": \"New York\",\n",
        "    \"NC\": \"North Carolina\",\"ND\": \"North Dakota\",\"OH\": \"Ohio\",\"OK\": \"Oklahoma\",\n",
        "    \"OR\": \"Oregon\",\"PA\": \"Pennsylvania\",\"RI\": \"Rhode Island\",\"SC\": \"South Carolina\",\n",
        "    \"SD\": \"South Dakota\",\"TN\": \"Tennessee\",\"TX\": \"Texas\",\"UT\": \"Utah\",\"VT\": \"Vermont\",\n",
        "    \"VA\": \"Virginia\",\"WA\": \"Washington\",\"WV\": \"West Virginia\",\"WI\": \"Wisconsin\",\"WY\": \"Wyoming\"\n",
        "}\n",
        "_US_STATE_NAMES = set(_US_STATE_ABBR_TO_NAME.values())\n",
        "_TERRITORY_ABBRS = {\"PR\", \"GU\", \"VI\", \"AS\", \"MP\"}\n",
        "\n",
        "_SUFFIX_PATTERNS = [\n",
        "    r\"\\bcounty\\b\", r\"\\bparish\\b\", r\"\\bborough\\b\", r\"\\bcensus\\s+area\\b\",\n",
        "    r\"\\bmunicipality\\b\", r\"\\bmunicipio\\b\", r\"\\bcity\\s+and\\s+borough\\b\", r\"\\bcity\\b\",\n",
        "]\n",
        "\n",
        "# -----------------------------\n",
        "# Dataclasses\n",
        "# -----------------------------\n",
        "@dataclass\n",
        "class GDPRow:\n",
        "    state_name: str\n",
        "    county_norm: str\n",
        "    real_gdp_2023_dollars: Optional[int]\n",
        "    gdp_rank_in_state_2023: Optional[int]\n",
        "    pct_change_2023: Optional[float]\n",
        "    pct_change_rank_in_state_2023: Optional[int]\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Helpers\n",
        "# -----------------------------\n",
        "def _is_nan(v: Any) -> bool:\n",
        "    try:\n",
        "        return v is None or pd.isna(v)\n",
        "    except Exception:\n",
        "        return v is None\n",
        "\n",
        "def _to_str(v: Any) -> Optional[str]:\n",
        "    if _is_nan(v):\n",
        "        return None\n",
        "    s = str(v).strip()\n",
        "    return s if s else None\n",
        "\n",
        "def _to_float_safe(v: Any) -> Optional[float]:\n",
        "    try:\n",
        "        if _is_nan(v):\n",
        "            return None\n",
        "        if isinstance(v, str):\n",
        "            s = v.strip()\n",
        "            if s in {\"\", \"--\", \"(D)\", \"(NA)\"}:\n",
        "                return None\n",
        "            return float(s.replace(\",\", \"\"))\n",
        "        return float(v)\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "def _to_int_safe(v: Any) -> Optional[int]:\n",
        "    f = _to_float_safe(v)\n",
        "    if f is None:\n",
        "        return None\n",
        "    try:\n",
        "        return int(f)\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "def _normalize_county_name(name: str) -> str:\n",
        "    if not name:\n",
        "        return \"\"\n",
        "    s = str(name).strip().lower()\n",
        "\n",
        "    # Drop anything after a comma\n",
        "    if \",\" in s:\n",
        "        s = s.split(\",\", 1)[0].strip()\n",
        "\n",
        "    # \"County of X\"\n",
        "    s = re.sub(r\"^\\s*county\\s+of\\s+\", \"\", s)\n",
        "\n",
        "    # punctuation normalization\n",
        "    s = s.replace(\"&\", \" and \")\n",
        "    s = s.replace(\"-\", \" \")\n",
        "    s = s.replace(\".\", \"\")\n",
        "    s = s.replace(\"â€™\", \"'\")\n",
        "    s = re.sub(r\"\\bst\\b\", \"saint\", s)\n",
        "\n",
        "    # strip suffix types\n",
        "    for pat in _SUFFIX_PATTERNS:\n",
        "        s = re.sub(pat, \" \", s)\n",
        "\n",
        "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
        "    return s\n",
        "\n",
        "def _state_abbr_to_name(abbr: str) -> Optional[str]:\n",
        "    return _US_STATE_ABBR_TO_NAME.get(abbr)\n",
        "\n",
        "def _is_us_total(name: str) -> bool:\n",
        "    return name.strip().lower() == \"united states\"\n",
        "\n",
        "def _looks_like_state_row(name: str, rank_cell: Any) -> bool:\n",
        "    \"\"\"\n",
        "    In this workbook format:\n",
        "      - State rows have name == state full name AND rank in state is '--' (or blank)\n",
        "      - County rows have an integer rank in state (even if county name equals a state name, e.g. \"Iowa\" county)\n",
        "    \"\"\"\n",
        "    if name not in _US_STATE_NAMES:\n",
        "        return False\n",
        "    s = _to_str(rank_cell)\n",
        "    if s is None:\n",
        "        return True\n",
        "    return s.strip() == \"--\"\n",
        "\n",
        "# -----------------------------\n",
        "# Excel Parsing (fixed-column BEA layout)\n",
        "# -----------------------------\n",
        "def _parse_county_gdp_excel(\n",
        "    path: str\n",
        ") -> Tuple[Dict[Tuple[str, str], GDPRow], int, int, int]:\n",
        "    \"\"\"\n",
        "    Parses CountyGDP_12_2024.xlsx using fixed columns observed in the file:\n",
        "\n",
        "    Col 0: GeoName (United States / State / County)\n",
        "    Col 1: 2023 Real GDP (thousands of chained dollars)\n",
        "    Col 5: 2023 rank in state (for GDP)  (state rows show '--')\n",
        "    Col 6: 2023 percent change\n",
        "    Col 9: 2023 rank in state (for percent change) (state rows show '--')\n",
        "\n",
        "    Returns:\n",
        "      gdp_map[(state_name, county_norm)] -> GDPRow\n",
        "      spreadsheet_total_records\n",
        "      spreadsheet_included_records (county rows ingested)\n",
        "      spreadsheet_ignored_out_of_scope_records (headers/blanks/US/state rows/non-county)\n",
        "    \"\"\"\n",
        "    df = pd.read_excel(path, header=None, engine=\"openpyxl\")\n",
        "    rows = df.values.tolist()\n",
        "\n",
        "    gdp_map: Dict[Tuple[str, str], GDPRow] = {}\n",
        "\n",
        "    total_records = 0\n",
        "    included = 0\n",
        "    ignored = 0\n",
        "\n",
        "    current_state: Optional[str] = None\n",
        "\n",
        "    for r in rows:\n",
        "        # consider \"records\" as rows with a non-empty GeoName cell\n",
        "        name_raw = _to_str(r[0] if len(r) > 0 else None)\n",
        "        if not name_raw:\n",
        "            continue\n",
        "\n",
        "        total_records += 1\n",
        "        name = name_raw.strip()\n",
        "\n",
        "        # Ignore top header/title lines (they are not US/State/County)\n",
        "        # We'll treat them as out-of-scope unless they become state context.\n",
        "        if _is_us_total(name):\n",
        "            current_state = None\n",
        "            ignored += 1\n",
        "            continue\n",
        "\n",
        "        # Identify state row\n",
        "        rank_cell = r[5] if len(r) > 5 else None\n",
        "        if _looks_like_state_row(name, rank_cell):\n",
        "            current_state = name\n",
        "            ignored += 1\n",
        "            continue\n",
        "\n",
        "        # County rows require a current_state\n",
        "        if not current_state:\n",
        "            ignored += 1\n",
        "            continue\n",
        "\n",
        "        # Pull fields by fixed indices\n",
        "        gdp_thousands = _to_float_safe(r[1] if len(r) > 1 else None)\n",
        "        gdp_rank = _to_int_safe(r[5] if len(r) > 5 else None)\n",
        "        pct_change = _to_float_safe(r[6] if len(r) > 6 else None)\n",
        "        pct_rank = _to_int_safe(r[9] if len(r) > 9 else None)\n",
        "\n",
        "        # If GDP is missing, it's not a county record we can use\n",
        "        if gdp_thousands is None:\n",
        "            ignored += 1\n",
        "            continue\n",
        "\n",
        "        # Multiply thousands -> dollars (as requested)\n",
        "        real_gdp_2023 = int(round(gdp_thousands * 1000.0))\n",
        "\n",
        "        county_norm = _normalize_county_name(name)\n",
        "\n",
        "        g = GDPRow(\n",
        "            state_name=current_state,\n",
        "            county_norm=county_norm,\n",
        "            real_gdp_2023_dollars=real_gdp_2023,\n",
        "            gdp_rank_in_state_2023=gdp_rank,\n",
        "            pct_change_2023=pct_change,\n",
        "            pct_change_rank_in_state_2023=pct_rank,\n",
        "        )\n",
        "        gdp_map[(current_state, county_norm)] = g\n",
        "        included += 1\n",
        "\n",
        "    ignored = max(0, total_records - included - sum(1 for _ in []))  # keep simple, ignored is computed below\n",
        "\n",
        "    # Better: compute ignored as total_records - included - (count of state/us rows we treated as ignored already)\n",
        "    # We already incremented ignored for those; so just return ignored as tracked.\n",
        "    # But we also incremented ignored for rows without current_state, etc. so it's accurate.\n",
        "    return gdp_map, total_records, included, ignored\n",
        "\n",
        "# -----------------------------\n",
        "# Main ETL Function\n",
        "# -----------------------------\n",
        "def EnrichCountyZipWithCountyGDPData(\n",
        "    argDbConnection: MongoClient,\n",
        "    argDBName: str = \"PublicHealthData\",\n",
        "    argSourceExcelFilePath: str = \"/mnt/data/CountyGDP_12_2024.xlsx\",\n",
        "    argSourceCollectionName: str = \"CountyZipNormalized\",\n",
        "    argDestinationCollectionName: str = \"CountyZipEnriched\",\n",
        ") -> List[Any]:\n",
        "    \"\"\"\n",
        "    Enriches CountyZipNormalized into CountyZipEnriched with 2023 county GDP measures.\n",
        "\n",
        "    - Skips Mongo source records where countyName is null (not inserted into destination)\n",
        "    - For territories (PR, GU, VI, AS, MP): inserts record with GDP fields = null\n",
        "    - For states: matches by (state full name, normalized county name)\n",
        "    - Drops destination collection before writing (drains it)\n",
        "    - Returns list of stats dictionaries as requested\n",
        "    \"\"\"\n",
        "\n",
        "    gdp_map, spreadsheet_total, spreadsheet_included, spreadsheet_ignored = _parse_county_gdp_excel(argSourceExcelFilePath)\n",
        "\n",
        "    db = argDbConnection[argDBName]\n",
        "    src: Collection = db[argSourceCollectionName]\n",
        "    dst: Collection = db[argDestinationCollectionName]\n",
        "\n",
        "    # Drain destination collection if it exists\n",
        "    dst.drop()\n",
        "\n",
        "    mongo_source_total = src.count_documents({})\n",
        "\n",
        "    mongo_ignored_out_of_scope = 0  # countyName null\n",
        "    mongo_ignored_unmatched = 0\n",
        "    mongo_written = 0\n",
        "\n",
        "    # Use sets to avoid enormous duplicate lists in unmatched output\n",
        "    unmatched_sets: Dict[str, set] = {}\n",
        "\n",
        "    batch: List[Dict[str, Any]] = []\n",
        "    BATCH_SIZE = 5000\n",
        "\n",
        "    cursor = src.find({}, no_cursor_timeout=True)\n",
        "    try:\n",
        "        for doc in cursor:\n",
        "            county_name = doc.get(\"countyName\")\n",
        "            if not county_name:\n",
        "                mongo_ignored_out_of_scope += 1\n",
        "                continue\n",
        "\n",
        "            state_abbr = doc.get(\"state\")\n",
        "            doc.pop(\"_id\", None)\n",
        "\n",
        "            # Territories: keep record, GDP fields null\n",
        "            if state_abbr in _TERRITORY_ABBRS:\n",
        "                doc.update({\n",
        "                    \"realGDP2023\": None,\n",
        "                    \"gdpRankInState2023\": None,\n",
        "                    \"percentChange2023\": None,\n",
        "                    \"percentChangeRankInState2023\": None,\n",
        "                })\n",
        "            else:\n",
        "                state_name = _state_abbr_to_name(state_abbr) if state_abbr else None\n",
        "                county_norm = _normalize_county_name(county_name)\n",
        "\n",
        "                g = gdp_map.get((state_name, county_norm)) if state_name else None\n",
        "\n",
        "                if g is None:\n",
        "                    mongo_ignored_unmatched += 1\n",
        "                    key = state_name or \"UNKNOWN\"\n",
        "                    if key not in unmatched_sets:\n",
        "                        unmatched_sets[key] = set()\n",
        "                    unmatched_sets[key].add(str(county_name))\n",
        "\n",
        "                    doc.update({\n",
        "                        \"realGDP2023\": None,\n",
        "                        \"gdpRankInState2023\": None,\n",
        "                        \"percentChange2023\": None,\n",
        "                        \"percentChangeRankInState2023\": None,\n",
        "                    })\n",
        "                else:\n",
        "                    doc.update({\n",
        "                        \"realGDP2023\": g.real_gdp_2023_dollars,\n",
        "                        \"gdpRankInState2023\": g.gdp_rank_in_state_2023,\n",
        "                        \"percentChange2023\": g.pct_change_2023,\n",
        "                        \"percentChangeRankInState2023\": g.pct_change_rank_in_state_2023,\n",
        "                    })\n",
        "\n",
        "            batch.append(doc)\n",
        "            mongo_written += 1\n",
        "\n",
        "            if len(batch) >= BATCH_SIZE:\n",
        "                dst.insert_many(batch, ordered=False)\n",
        "                batch.clear()\n",
        "\n",
        "        if batch:\n",
        "            dst.insert_many(batch, ordered=False)\n",
        "            batch.clear()\n",
        "\n",
        "    finally:\n",
        "        try:\n",
        "            cursor.close()\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    unmatched_counties_by_state: Dict[str, List[str]] = {\n",
        "        state: sorted(list(names)) for state, names in unmatched_sets.items()\n",
        "    }\n",
        "\n",
        "    return [\n",
        "        {\"spreadsheet_ignored_out_of_scope_records\": spreadsheet_ignored},\n",
        "        {\"spreadsheet_included_records\": spreadsheet_included},\n",
        "        {\"spreadsheet_total_records\": spreadsheet_total},\n",
        "        {\"mongo_source_total_records\": mongo_source_total},\n",
        "        {\"mongo_records_ignored_out_of_scope\": mongo_ignored_out_of_scope},\n",
        "        {\"mongo_records_ignored_unmatched_county_name\": mongo_ignored_unmatched},\n",
        "        {\"mongo_records_written_to_destination\": mongo_written},\n",
        "        {\"unmatched_counties_by_state\": unmatched_counties_by_state},\n",
        "        {\"run_stats_full\": {\n",
        "            \"spreadsheet_total_records\": spreadsheet_total,\n",
        "            \"spreadsheet_included_records\": spreadsheet_included,\n",
        "            \"spreadsheet_ignored_out_of_scope_records\": spreadsheet_ignored,\n",
        "            \"mongo_source_total_records\": mongo_source_total,\n",
        "            \"mongo_records_ignored_out_of_scope\": mongo_ignored_out_of_scope,\n",
        "            \"mongo_records_ignored_unmatched_county_name\": mongo_ignored_unmatched,\n",
        "            \"mongo_records_written_to_destination\": mongo_written,\n",
        "            \"unmatched_counties_by_state\": unmatched_counties_by_state,\n",
        "        }},\n",
        "    ]\n",
        "\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Driver"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "zipCountyCSVPath=r\"C:\\chatHealthy\\Resources\\ZIP_COUNTY_092025.csv\"\n",
        "CountyFipsNameFilePath=r\"C:\\chatHealthy\\Resources\\all-geocodes-v2021.csv\"\n",
        "GDP_FILE_PATH=r\"C:\\chatHealthy\\Resources\\CountyGDP_12_2024.xlsx\" \n",
        "\n",
        "\n",
        "'''\n",
        "stats = results = load_county_zip_with_census_collections(\n",
        "    argDbConnection=DbUtil.getConnection(),\n",
        "    argDatabaseName=\"PublicHealthData\",\n",
        "    argHudCountyZipCsvPath=zipCountyCSVPath,\n",
        "    argCountyFipsNameFilePath=CountyFipsNameFilePath,\n",
        "    argHudNormalizedCollectionName=\"CountyZipNormalized\",\n",
        "    argCountyLookupCollectionName=\"CountyFipsLookup\",\n",
        "    argCensusCrosswalkCollectionName=\"HudZipCountyRaw\",\n",
        ")\n",
        "'''\n",
        "stats = EnrichCountyZipWithCountyGDPData(\n",
        "    argDbConnection=DbUtil.getConnection(),\n",
        "    argDBName=\"PublicHealthData\",\n",
        "    argSourceExcelFilePath=GDP_FILE_PATH,\n",
        "    argSourceCollectionName=\"CountyZipNormalized\",\n",
        "    argDestinationCollectionName=\"CountyZipEnriched\",\n",
        ")\n",
        "for item in stats:\n",
        "    print(item)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'spreadsheet_ignored_out_of_scope_records': 57}\n",
            "{'spreadsheet_included_records': 3113}\n",
            "{'spreadsheet_total_records': 3170}\n",
            "{'mongo_source_total_records': 39493}\n",
            "{'mongo_records_ignored_out_of_scope': 430}\n",
            "{'mongo_records_ignored_unmatched_county_name': 469}\n",
            "{'mongo_records_written_to_destination': 39063}\n",
            "{'unmatched_counties_by_state': {'Virginia': ['Albemarle County', 'Alleghany County', 'Bristol city', 'Buena Vista city', 'Campbell County', 'Carroll County', 'Charlottesville city', 'Colonial Heights city', 'Danville city', 'Emporia city', 'Falls Church city', 'Frederick County', 'Fredericksburg city', 'Galax city', 'Greensville County', 'Harrisonburg city', 'Henry County', 'Hopewell city', 'James City County', 'Lexington city', 'Lynchburg city', 'Manassas Park city', 'Manassas city', 'Montgomery County', 'Norton city', 'Petersburg city', 'Pittsylvania County', 'Poquoson city', 'Prince George County', 'Radford city', 'Rockingham County', 'Salem city', 'Southampton County', 'Spotsylvania County', 'Staunton city', 'Washington County', 'Waynesboro city', 'Williamsburg city', 'Winchester city', 'Wise County', 'York County'], 'District of Columbia': ['Arlington County', 'District of Columbia', 'Fairfax County', 'Montgomery County', \"Prince George's County\"], 'New Hampshire': ['York County'], 'Ohio': ['Boone County', 'Kenton County'], 'Idaho': ['Fremont County'], 'Hawaii': ['Kalawao County', 'Maui County']}}\n",
            "{'run_stats_full': {'spreadsheet_total_records': 3170, 'spreadsheet_included_records': 3113, 'spreadsheet_ignored_out_of_scope_records': 57, 'mongo_source_total_records': 39493, 'mongo_records_ignored_out_of_scope': 430, 'mongo_records_ignored_unmatched_county_name': 469, 'mongo_records_written_to_destination': 39063, 'unmatched_counties_by_state': {'Virginia': ['Albemarle County', 'Alleghany County', 'Bristol city', 'Buena Vista city', 'Campbell County', 'Carroll County', 'Charlottesville city', 'Colonial Heights city', 'Danville city', 'Emporia city', 'Falls Church city', 'Frederick County', 'Fredericksburg city', 'Galax city', 'Greensville County', 'Harrisonburg city', 'Henry County', 'Hopewell city', 'James City County', 'Lexington city', 'Lynchburg city', 'Manassas Park city', 'Manassas city', 'Montgomery County', 'Norton city', 'Petersburg city', 'Pittsylvania County', 'Poquoson city', 'Prince George County', 'Radford city', 'Rockingham County', 'Salem city', 'Southampton County', 'Spotsylvania County', 'Staunton city', 'Washington County', 'Waynesboro city', 'Williamsburg city', 'Winchester city', 'Wise County', 'York County'], 'District of Columbia': ['Arlington County', 'District of Columbia', 'Fairfax County', 'Montgomery County', \"Prince George's County\"], 'New Hampshire': ['York County'], 'Ohio': ['Boone County', 'Kenton County'], 'Idaho': ['Fremont County'], 'Hawaii': ['Kalawao County', 'Maui County']}}}\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}