{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "61727436",
      "metadata": {},
      "source": [
        "<div style=\"font-size: calc(1em - 5pt);\">\n",
        "- Do imports\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36d071aa",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install dependencies (run once)\n",
        "%pip install -U langchain-openai langchain-core pymongo ipython\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5683506",
      "metadata": {},
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "# Standard library imports\n",
        "import os\n",
        "import csv\n",
        "from datetime import datetime, timezone\n",
        "from typing import Dict, List, Any, Optional\n",
        "\n",
        "# Third-party imports\n",
        "from bson import json_util\n",
        "from pymongo import MongoClient\n",
        "from pymongo.errors import PyMongoError\n",
        "\n",
        "# LangChain imports\n",
        "from langchain_core.documents import Document\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "# IPython imports\n",
        "from IPython import get_ipython\n",
        "\n",
        "# Configuration\n",
        "debug = True\n",
        "specialtyMetaDataFilePath = r\"C:\\chatHealthy\\Resources\\nucc_taxonomy_250.csv\"\n",
        "specialtyMetaDataCollectionName = \"SpecialtyMetaData\"\n",
        "specialtyMetaDataVectorollectionName = \"SpecialtyMetaDataVectors\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36d584d8",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def getDBConnection() -> MongoClient:\n",
        "    \"\"\"\n",
        "    Creates and returns a MongoDB client using the connection string stored\n",
        "    in the MONGO_connectionString environment variable.\n",
        "\n",
        "    The caller is responsible for closing the client.\n",
        "    \"\"\"\n",
        "    conn_str = os.getenv(\"MONGO_connectionString\")\n",
        "\n",
        "    if not conn_str:\n",
        "        raise EnvironmentError(\n",
        "            \"Environment variable 'MONGO_connectionString' is not set.\"\n",
        "        )\n",
        "\n",
        "    try:\n",
        "        client = MongoClient(conn_str)\n",
        "\n",
        "        # Lightweight health check\n",
        "        client.admin.command(\"ping\")\n",
        "        print(\"DB client was sucsessfully created\")\n",
        "\n",
        "        return client\n",
        "\n",
        "    except PyMongoError as e:\n",
        "        raise ConnectionError(\n",
        "            f\"Failed to connect to MongoDB: {e}\"\n",
        "        ) from e\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d22c24ba",
      "metadata": {},
      "source": [
        "Store metadata for US medical specialties. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6fdff2c5",
      "metadata": {},
      "outputs": [],
      "source": [
        "def createSpecialtyMetaDataCollection(\n",
        "    client: MongoClient,\n",
        "    csvPath: str,\n",
        "    argCcollectionName: str,\n",
        "    batchSize: int\n",
        ") -> int:\n",
        "    \"\"\"\n",
        "    Creates or refreshes the PublicHealthData.SpecialtyMetaData collection.\n",
        "\n",
        "    Behavior:\n",
        "    - Uses database: PublicHealthData\n",
        "    - Uses collection: SpecialtyMetaData\n",
        "    - If the collection exists, it is emptied\n",
        "    - CSV row 1 is treated as field names\n",
        "    - All CSV rows are inserted as documents\n",
        "    - Inserts occur in batches\n",
        "\n",
        "    Args:\n",
        "        client: Connected MongoClient (LearnAIMongoDB cluster)\n",
        "        csvPath: Absolute path to the CSV file\n",
        "        batchSize: Number of documents per insert_many batch\n",
        "\n",
        "    Returns:\n",
        "        Total number of documents inserted\n",
        "    \"\"\"\n",
        "    if client is None:\n",
        "        raise ValueError(\"client must be a valid MongoClient\")\n",
        "\n",
        "    if not csvPath:\n",
        "        raise ValueError(\"csvPath must be provided\")\n",
        "    if not argCcollectionName:\n",
        "        raise ValueError(\"argCcollectionName must be provided\")\n",
        "    if batchSize <= 0:\n",
        "        raise ValueError(\"batchSize must be > 0\")\n",
        "\n",
        "    db = client[\"PublicHealthData\"]\n",
        "    collection = db[argCcollectionName]\n",
        "\n",
        "    try:\n",
        "        # Empty collection if it already exists\n",
        "        collection.delete_many({})\n",
        "\n",
        "        inserted_total = 0\n",
        "        batch: List[Dict[str, Any]] = []\n",
        "\n",
        "        # utf-8-sig handles BOM if present\n",
        "        with open(csvPath, mode=\"r\", newline=\"\", encoding=\"utf-8-sig\") as csv_file:\n",
        "            reader = csv.DictReader(csv_file)\n",
        "\n",
        "            if not reader.fieldnames:\n",
        "                raise ValueError(\"CSV file does not contain a header row\")\n",
        "\n",
        "            for row in reader:\n",
        "                document = {\n",
        "                    key.strip(): value.strip() if isinstance(value, str) else value\n",
        "                    for key, value in row.items()\n",
        "                }\n",
        "\n",
        "                batch.append(document)\n",
        "\n",
        "                if len(batch) >= batchSize:\n",
        "                    result = collection.insert_many(batch, ordered=False)\n",
        "                    inserted_total += len(result.inserted_ids)\n",
        "                    batch.clear()\n",
        "\n",
        "        # Insert any remaining records\n",
        "        if batch:\n",
        "            result = collection.insert_many(batch, ordered=False)\n",
        "            inserted_total += len(result.inserted_ids)\n",
        "\n",
        "        return inserted_total\n",
        "\n",
        "    except FileNotFoundError as e:\n",
        "        raise FileNotFoundError(f\"CSV file not found: {csvPath}\") from e\n",
        "\n",
        "    except PyMongoError as e:\n",
        "        raise RuntimeError(\n",
        "            f\"MongoDB error while loading PublicHealthData.SpecialtyMetaData: {e}\"\n",
        "        ) from e\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05072b38",
      "metadata": {},
      "outputs": [],
      "source": [
        "def _first_present(doc: Dict[str, Any], keys: List[str]) -> Optional[Any]:\n",
        "    \"\"\"\n",
        "    Returns the value of the first key in 'keys' that exists in 'doc'.\n",
        "    Returns None if none of the keys are present.\n",
        "    \"\"\"\n",
        "    for key in keys:\n",
        "        if key in doc and doc[key] is not None:\n",
        "            return doc[key]\n",
        "    return None\n",
        "\n",
        "\n",
        "def _add_all_attributes_to_metadata(\n",
        "    mongo_doc: Dict[str, Any],\n",
        "    base_metadata: Dict[str, Any]\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Merges all attributes from mongo_doc into base_metadata.\n",
        "    Converts values to strings and handles special types.\n",
        "    \"\"\"\n",
        "    result = base_metadata.copy()\n",
        "    \n",
        "    for key, value in mongo_doc.items():\n",
        "        # Skip keys that are already in base_metadata\n",
        "        if key in base_metadata:\n",
        "            continue\n",
        "            \n",
        "        # Convert value to string, handling None and special types\n",
        "        if value is None:\n",
        "            result[key] = None\n",
        "        elif isinstance(value, (str, int, float, bool)):\n",
        "            result[key] = value\n",
        "        else:\n",
        "            # For complex types (lists, dicts, ObjectId, etc.), convert to string\n",
        "            result[key] = str(value)\n",
        "    \n",
        "    return result\n",
        "\n",
        "\n",
        "def _safe_to_text(mongo_doc: Dict[str, Any]) -> str:\n",
        "    \"\"\"\n",
        "    Safely converts a MongoDB document to a text representation.\n",
        "    Uses json_util to handle BSON types like ObjectId, datetime, etc.\n",
        "    \"\"\"\n",
        "    return json_util.dumps(mongo_doc, indent=2, default=str)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e716930",
      "metadata": {},
      "source": [
        "Chunk the speciatly metadata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63ff30b3",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def build_taxonomy_documents_from_mongo(\n",
        "    client: MongoClient,\n",
        "    collection_name: str = \"SpecialtyMetaData\",\n",
        ") -> List[Document]:\n",
        "    db = client[\"PublicHealthData\"]\n",
        "    col = db[collection_name]\n",
        "\n",
        "    docs: List[Document] = []\n",
        "\n",
        "    for rec in col.find({}):\n",
        "        code = rec.get(\"Code\", \"\") or \"\"\n",
        "        classification = rec.get(\"Classification\", \"\") or \"\"\n",
        "        specialization = rec.get(\"Specialization\", \"\") or \"\"\n",
        "        display_name = rec.get(\"Display Name\", \"\") or rec.get(\"DisplayName\", \"\") or \"\"\n",
        "        definition = rec.get(\"Definition\", \"\") or \"\"\n",
        "        grouping = rec.get(\"Grouping\", \"\") or \"\"\n",
        "        section = rec.get(\"Section\", \"\") or \"\"\n",
        "\n",
        "        # This is the text you embed. Keep it focused, human-language, searchable.\n",
        "        text = (\n",
        "            f\"Code: {code}\\n\"\n",
        "            f\"Display Name: {display_name}\\n\"\n",
        "            f\"Classification: {classification}\\n\"\n",
        "            f\"Specialization: {specialization}\\n\"\n",
        "            f\"Grouping: {grouping}\\n\"\n",
        "            f\"Section: {section}\\n\"\n",
        "            f\"Definition: {definition}\\n\"\n",
        "        )\n",
        "\n",
        "        docs.append(\n",
        "            Document(\n",
        "                page_content=text,\n",
        "                metadata={\n",
        "                    \"doc_kind\": \"taxonomy\",\n",
        "                    \"collection\": collection_name,\n",
        "                    \"Code\": code,\n",
        "                    \"Classification\": classification,\n",
        "                    \"Specialization\": specialization,\n",
        "                    \"DisplayName\": display_name,\n",
        "                    \"Grouping\": grouping,\n",
        "                    \"Section\": section,\n",
        "                },\n",
        "            )\n",
        "        )\n",
        "\n",
        "    return docs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "803d41ac",
      "metadata": {},
      "source": [
        "encode the specialty metadata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a253dbd5",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def encode_documents_openai(\n",
        "    docs: List[Document],\n",
        "    model_name: str,\n",
        "    batch_size: int,\n",
        ") -> List[List[float]]:\n",
        "    \"\"\"\n",
        "    Encodes LangChain Documents into embedding vectors using OpenAI.\n",
        "\n",
        "    Args:\n",
        "      docs: list of Documents (use taxonomy docs for day 1)\n",
        "      model_name: e.g. \"text-embedding-3-large\" (best fidelity)\n",
        "      batch_size: how many docs per request (128 is a safe starting point)\n",
        "\n",
        "    Returns:\n",
        "      vectors where vectors[i] corresponds to docs[i]\n",
        "    \"\"\"\n",
        "    if not docs:\n",
        "        raise ValueError(\"docs is empty\")\n",
        "    if batch_size <= 0:\n",
        "        raise ValueError(\"batch_size must be > 0\")\n",
        "    if not model_name:\n",
        "        raise ValueError(\"model_name is required\")\n",
        "\n",
        "    embeddings = OpenAIEmbeddings(model=model_name)\n",
        "\n",
        "    # Sanity check: dimension\n",
        "    dims = len(embeddings.embed_query(\"dimension check\"))\n",
        "    print(f\"Embedding model: {model_name} (dims={dims})\")\n",
        "\n",
        "    texts = [d.page_content for d in docs]\n",
        "    total = len(texts)\n",
        "\n",
        "    vectors: List[List[float]] = []\n",
        "    for start in range(0, total, batch_size):\n",
        "        end = min(start + batch_size, total)\n",
        "        vectors.extend(embeddings.embed_documents(texts[start:end]))\n",
        "        \n",
        "\n",
        "    return vectors\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0ddbb80",
      "metadata": {},
      "source": [
        "Store vectors in DB\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c9a7cf3",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def store_embeddings_in_mongo(\n",
        "    client: MongoClient,\n",
        "    db_name: str,\n",
        "    target_collection_name: str,\n",
        "    source_collection_name: str,\n",
        "    docs: List[Document],\n",
        "    vectors: List[List[float]],\n",
        "    batch_size: int,\n",
        "    wipe_collection_first: bool,\n",
        ") -> int:\n",
        "    \"\"\"\n",
        "    Stores (text + embedding + metadata) into MongoDB.\n",
        "\n",
        "    This works in ANY MongoDB tier (it's just normal inserts).\n",
        "    If you later use Atlas Vector Search, you'll create an Atlas vector index on `embedding`.\n",
        "\n",
        "    Args:\n",
        "        client: Connected MongoClient\n",
        "        db_name: Database name\n",
        "        source_collection_name: Name of the source collection (for reference)\n",
        "        target_collection_name: Name of the target collection where vectors will be stored\n",
        "        docs: List of Document objects to store\n",
        "        vectors: List of embedding vectors corresponding to docs\n",
        "        batch_size: Number of documents per insert batch\n",
        "        wipe_collection_first: If True, delete all documents in target collection before inserting\n",
        "\n",
        "    Stored schema per record:\n",
        "      {\n",
        "        \"text\": <page_content>,\n",
        "        \"embedding\": <vector>,\n",
        "        \"metadata\": <doc.metadata>,\n",
        "        \"Code\": <code_from_metadata>,  # Code stored as top-level for easy lookup\n",
        "        \"created_utc\": <timestamp>\n",
        "      }\n",
        "\n",
        "    Returns:\n",
        "      number of inserted documents\n",
        "    \"\"\"\n",
        "    if len(docs) != len(vectors):\n",
        "        raise ValueError(f\"docs and vectors must have same length. docs={len(docs)}, vectors={len(vectors)}\")\n",
        "    if batch_size <= 0:\n",
        "        raise ValueError(\"batch_size must be > 0\")\n",
        "    if not source_collection_name:\n",
        "        raise ValueError(\"source_collection_name must be provided\")\n",
        "    if not target_collection_name:\n",
        "        raise ValueError(\"target_collection_name must be provided\")\n",
        "\n",
        "    db = client[db_name]\n",
        "    col = db[target_collection_name]\n",
        "\n",
        "    if wipe_collection_first:\n",
        "        col.delete_many({})\n",
        "        print(f\"Wiped collection {db_name}.{target_collection_name}\")\n",
        "\n",
        "    inserted = 0\n",
        "    now = datetime.now(timezone.utc)\n",
        "\n",
        "    buffer: List[Dict[str, Any]] = []\n",
        "    for doc, vec in zip(docs, vectors):\n",
        "        # Extract Code from metadata for top-level access\n",
        "        code = doc.metadata.get(\"Code\", \"\") if doc.metadata else \"\"\n",
        "        \n",
        "        buffer.append(\n",
        "            {\n",
        "                \"text\": doc.page_content,\n",
        "                \"embedding\": vec,\n",
        "                \"metadata\": doc.metadata,\n",
        "                \"Code\": code,  # Store Code as top-level attribute for easy lookup\n",
        "                \"created_utc\": now,\n",
        "            }\n",
        "        )\n",
        "\n",
        "        if len(buffer) >= batch_size:\n",
        "            res = col.insert_many(buffer, ordered=False)\n",
        "            inserted += len(res.inserted_ids)\n",
        "            buffer.clear()\n",
        "            print(f\"Inserted {inserted}/{len(docs)}\")\n",
        "\n",
        "    if buffer:\n",
        "        res = col.insert_many(buffer, ordered=False)\n",
        "        inserted += len(res.inserted_ids)\n",
        "        print(f\"Inserted {inserted}/{len(docs)}\")\n",
        "\n",
        "    print(f\"Done. Inserted {inserted} records into {db_name}.{target_collection_name}\")\n",
        "    return inserted\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a441e493",
      "metadata": {},
      "source": [
        "Driver "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7657cd59",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get the current IPython instance\n",
        "ipython = get_ipython()\n",
        "if ipython is not None:\n",
        "    # Set the output limit to 30K characters (30000 bytes)\n",
        "    ipython.display_formatter.max_output_size = 30000\n",
        "    \n",
        "\n",
        "db=getDBConnection()\n",
        "t=createSpecialtyMetaDataCollection(db,specialtyMetaDataFilePath, specialtyMetaDataCollectionName, 128)\n",
        "if debug==True:\n",
        "   print(\"{} Total number of specialty metadata documents inserted\".format(t))      \n",
        "documents=build_taxonomy_documents_from_mongo(db,\"SpecialtyMetaData\")\n",
        "if debug==True:\n",
        "    print(f\"\\nTOTAL NUMBER OF CHUNKS: {len(documents)}\\n\")\n",
        "    print(\"\\n===== CHUNKS 10-15 =====\\n\")\n",
        "    for i, chunk in enumerate(documents[10:15], start=10):\n",
        "        print(f\"--- Chunk {i} ---\")\n",
        "        print(chunk.page_content)  # Removed [:500] to show full content\n",
        "        print(\"\\n\\n\")\n",
        "    \n",
        "vectors=encode_documents_openai(documents,\"text-embedding-3-large\",128)\n",
        "if debug==True:\n",
        "    print(f\"\\nTOTAL NUMBER OF VECTORS: {len(vectors)}\\n\")\n",
        "    print(\"\\n===== VECTORS 10-15 =====\\n\")\n",
        "    for i, vector in enumerate(vectors[10:15], start=10):\n",
        "        print(f\"--- Vector {i} ---\")\n",
        "        print(vector)\n",
        "        print(\"\\n\\n\")\n",
        "  \n",
        "target_collection_name = \"SpecialtyMetaDataVectors\"\n",
        "source_collection_name = \"SpecialtyMetaData\"\n",
        "store_embeddings_in_mongo(db,\"PublicHealthData\",specialtyMetaDataVectorollectionName,specialtyMetaDataCollectionName,documents,vectors,128,True)\n",
        "\n",
        " \n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
