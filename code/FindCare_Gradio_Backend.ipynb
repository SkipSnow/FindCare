{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# FindCare â€” Gradio Backend (Notebook)\n",
        "\n",
        "**File:** FindCare_Gradio_Backend.ipynb  \n",
        "**Author:** Skip Snow  \n",
        "**Co-Author:** GPT-5  \n",
        "**Copyright:** Copyright (c) 2025 Skip Snow. All rights reserved.\n",
        "\n",
        "This notebook implements a **Gradio + FastAPI** backend that matches the frontend webhook/API expectations in your provided spec.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# If needed, install dependencies (uncomment in a fresh environment)\n",
        "# !pip -q install gradio fastapi uvicorn python-multipart pydantic\n",
        "\n",
        "import os\n",
        "import gradio as gr\n",
        "from fastapi import Request, UploadFile, File, Form\n",
        "from fastapi.responses import JSONResponse\n",
        "from fastapi.middleware.cors import CORSMiddleware\n",
        "from pydantic import BaseModel\n",
        "from typing import List, Optional, Dict, Any\n",
        "import uuid\n",
        "import time\n",
        "import json\n",
        "import re\n",
        "import socket\n",
        "import socket\n",
        "import socket\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) In-memory session store (replace with Redis/Mongo later)\n",
        "\n",
        "The frontend currently sends **no session id**, so we keep a simple global session. If you later add a header or cookie, you can key sessions by that value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# In-memory session storage (keyed by session ID from cookie)\n",
        "# In production, replace with Redis/MongoDB\n",
        "_sessions: Dict[str, dict] = {}\n",
        "\n",
        "def get_or_create_session_id(request: Request) -> str:\n",
        "    \"\"\"Get session ID from cookie, or create a new one.\"\"\"\n",
        "    session_id = request.cookies.get(\"findCareSession\")\n",
        "    if not session_id:\n",
        "        session_id = str(uuid.uuid4())\n",
        "    return session_id\n",
        "\n",
        "def get_session(session_id: str) -> dict:\n",
        "    \"\"\"Get session data, creating if it doesn't exist.\"\"\"\n",
        "    if session_id not in _sessions:\n",
        "        _sessions[session_id] = {\n",
        "            \"created_at\": time.time(),\n",
        "            \"prompts\": [],\n",
        "            \"results\": [],\n",
        "            \"copies\": [],\n",
        "            \"deletes\": [],\n",
        "            \"selected_state\": None,\n",
        "            \"model\": \"mock-default\",\n",
        "        }\n",
        "    return _sessions[session_id]\n",
        "\n",
        "def set_session_cookie(response: JSONResponse, session_id: str):\n",
        "    \"\"\"Set the secure cookie with session ID.\"\"\"\n",
        "    # Use secure=True in production (HTTPS), False for local development (HTTP)\n",
        "    is_production = os.getenv(\"ENVIRONMENT\", \"development\").lower() == \"production\"\n",
        "    \n",
        "    response.set_cookie(\n",
        "        key=\"findCareSession\",\n",
        "        value=session_id,\n",
        "        httponly=True,\n",
        "        secure=is_production,  # Only send over HTTPS in production\n",
        "        samesite=\"lax\",\n",
        "        max_age=86400 * 30  # 30 days\n",
        "    )\n",
        "\n",
        "class SessionStore:\n",
        "    \"\"\"Wrapper to access session data for a given request.\"\"\"\n",
        "    \n",
        "    def __init__(self, request: Request, response: Optional[JSONResponse] = None):\n",
        "        self.session_id = get_or_create_session_id(request)\n",
        "        self._session = get_session(self.session_id)\n",
        "        self.response = response\n",
        "        \n",
        "    def add_prompt(self, prompt: str):\n",
        "        self._session[\"prompts\"].append(prompt)\n",
        "        \n",
        "    def set_results(self, results: List[dict]):\n",
        "        self._session[\"results\"] = results\n",
        "        \n",
        "    def delete_result(self, result_id: int):\n",
        "        self._session[\"deletes\"].append({\"resultId\": result_id, \"ts\": time.time()})\n",
        "        self._session[\"results\"] = [r for r in self._session[\"results\"] if r.get(\"id\") != result_id]\n",
        "        \n",
        "    def copy_result(self, result_id: int):\n",
        "        self._session[\"copies\"].append({\"resultId\": result_id, \"ts\": time.time()})\n",
        "        \n",
        "    def set_state(self, state: str):\n",
        "        self._session[\"selected_state\"] = state\n",
        "        \n",
        "    def set_model(self, model_id: str):\n",
        "        self._session[\"model\"] = model_id\n",
        "        \n",
        "    def transcript_text(self) -> str:\n",
        "        lines = []\n",
        "        for i, p in enumerate(self._session[\"prompts\"], start=1):\n",
        "            lines.append(f\"User[{i}]: {p}\")\n",
        "        return \"\\n\".join(lines)\n",
        "        \n",
        "    def summary_text(self) -> str:\n",
        "        if not self._session[\"prompts\"]:\n",
        "            return \"No queries yet.\"\n",
        "        last = self._session[\"prompts\"][-1]\n",
        "        return f\"Session includes {len(self._session['prompts'])} query(ies). Most recent request: {last}\"\n",
        "        \n",
        "    @property\n",
        "    def data(self):\n",
        "        return self._session\n",
        "        \n",
        "    def set_cookie_on_response(self, response: JSONResponse):\n",
        "        \"\"\"Set the session cookie on the response.\"\"\"\n",
        "        set_session_cookie(response, self.session_id)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Mock provider search\n",
        "\n",
        "Replace this with your real provider/specialty lookup (Mongo, vector search, etc.)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "STATE_ABBR = {\n",
        "    \"Alabama\":\"AL\",\"Alaska\":\"AK\",\"Arizona\":\"AZ\",\"Arkansas\":\"AR\",\"California\":\"CA\",\"Colorado\":\"CO\",\"Connecticut\":\"CT\",\n",
        "    \"Delaware\":\"DE\",\"Florida\":\"FL\",\"Georgia\":\"GA\",\"Hawaii\":\"HI\",\"Idaho\":\"ID\",\"Illinois\":\"IL\",\"Indiana\":\"IN\",\"Iowa\":\"IA\",\n",
        "    \"Kansas\":\"KS\",\"Kentucky\":\"KY\",\"Louisiana\":\"LA\",\"Maine\":\"ME\",\"Maryland\":\"MD\",\"Massachusetts\":\"MA\",\"Michigan\":\"MI\",\n",
        "    \"Minnesota\":\"MN\",\"Mississippi\":\"MS\",\"Missouri\":\"MO\",\"Montana\":\"MT\",\"Nebraska\":\"NE\",\"Nevada\":\"NV\",\"New Hampshire\":\"NH\",\n",
        "    \"New Jersey\":\"NJ\",\"New York\":\"NY\",\"North Carolina\":\"NC\",\"North Dakota\":\"ND\",\"Ohio\":\"OH\",\"Oklahoma\":\"OK\",\"Oregon\":\"OR\",\n",
        "    \"Pennsylvania\":\"PA\",\"Rhode Island\":\"RI\",\"South Carolina\":\"SC\",\"South Dakota\":\"SD\",\"Tennessee\":\"TN\",\"Texas\":\"TX\",\"Utah\":\"UT\",\n",
        "    \"Vermont\":\"VT\",\"Virginia\":\"VA\",\"Washington\":\"WA\",\"West Virginia\":\"WV\",\"Wisconsin\":\"WI\",\"Wyoming\":\"WY\"\n",
        "}\n",
        "\n",
        "TYPE_COLOR = {\n",
        "    \"Hospital\": \"#3b82f6\",\n",
        "    \"Clinic\": \"#10b981\",\n",
        "    \"Urgent Care\": \"#f59e0b\",\n",
        "    \"Private Practice\": \"#8b5cf6\",\n",
        "    \"Imaging Center\": \"#ef4444\",\n",
        "}\n",
        "\n",
        "MOCK_PROVIDERS = [\n",
        "    {\"name\":\"General Hospital\", \"type\":\"Hospital\", \"states\":[\"CA\",\"TX\",\"FL\",\"NY\"], \"distance\":\"2.3 miles\"},\n",
        "    {\"name\":\"Family Care Clinic\", \"type\":\"Clinic\", \"states\":[\"CA\",\"WA\",\"OR\",\"NV\"], \"distance\":\"1.8 miles\"},\n",
        "    {\"name\":\"Urgent Care Center\", \"type\":\"Urgent Care\", \"states\":[\"TX\",\"LA\",\"OK\",\"AR\"], \"distance\":\"3.5 miles\"},\n",
        "    {\"name\":\"Heart & Vascular Associates\", \"type\":\"Private Practice\", \"states\":[\"CA\",\"NY\",\"PA\",\"MA\"], \"distance\":\"4.1 miles\"},\n",
        "    {\"name\":\"Advanced Imaging\", \"type\":\"Imaging Center\", \"states\":[\"FL\",\"GA\",\"NC\",\"SC\"], \"distance\":\"2.9 miles\"},\n",
        "]\n",
        "\n",
        "def _infer_state_from_text(prompt: str) -> Optional[str]:\n",
        "    # Accept \"CA\" or full state name\n",
        "    m = re.search(r\"\\b([A-Z]{2})\\b\", prompt)\n",
        "    if m:\n",
        "        abbr = m.group(1)\n",
        "        if abbr in set(STATE_ABBR.values()):\n",
        "            return abbr\n",
        "\n",
        "    lowered = prompt.lower()\n",
        "    for name, abbr in STATE_ABBR.items():\n",
        "        if name.lower() in lowered:\n",
        "            return abbr\n",
        "    return None\n",
        "\n",
        "def mock_search(prompt: str, selected_state: Optional[str]=None) -> List[dict]:\n",
        "    # Very simple intent heuristics\n",
        "    state = selected_state or _infer_state_from_text(prompt)\n",
        "    needle = prompt.lower().strip()\n",
        "\n",
        "    results = []\n",
        "    base_id = int(time.time() * 1000)\n",
        "\n",
        "    for i, p in enumerate(MOCK_PROVIDERS):\n",
        "        # Filter by state if available\n",
        "        if state and state not in p[\"states\"]:\n",
        "            continue\n",
        "\n",
        "        # Very light text filter by keywords\n",
        "        if needle:\n",
        "            if (\"cardio\" in needle) and (\"Heart\" not in p[\"name\"]):\n",
        "                # keep only the heart practice for cardio queries\n",
        "                continue\n",
        "            if (\"urgent\" in needle) and (p[\"type\"] != \"Urgent Care\"):\n",
        "                continue\n",
        "            if (\"imaging\" in needle or \"xray\" in needle or \"mri\" in needle) and (p[\"type\"] != \"Imaging Center\"):\n",
        "                continue\n",
        "\n",
        "        results.append({\n",
        "            \"id\": base_id + i,\n",
        "            \"name\": p[\"name\"],\n",
        "            \"type\": p[\"type\"],\n",
        "            \"color\": TYPE_COLOR.get(p[\"type\"], \"#6b7280\"),\n",
        "            \"distance\": p[\"distance\"],\n",
        "        })\n",
        "\n",
        "    # Always return something (frontend shows \"No results yet\" otherwise)\n",
        "    if not results:\n",
        "        results = [{\n",
        "            \"id\": base_id,\n",
        "            \"name\": \"No matching providers (mock)\",\n",
        "            \"type\": \"Clinic\",\n",
        "            \"color\": TYPE_COLOR[\"Clinic\"],\n",
        "            \"distance\": \"N/A\",\n",
        "        }]\n",
        "    return results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) File handling stub\n",
        "\n",
        "The frontend sends uploaded files as `multipart/form-data`. Here we extract lightweight text (filename + size). Replace with PDF/DOCX parsing + OCR when you wire it up."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "async def summarize_uploads(files: Optional[List[UploadFile]]) -> str:\n",
        "    if not files:\n",
        "        return \"\"\n",
        "    parts = []\n",
        "    for f in files:\n",
        "        try:\n",
        "            raw = await f.read()\n",
        "            parts.append(f\"{f.filename} ({len(raw)} bytes)\")\n",
        "        except Exception:\n",
        "            parts.append(f\"{getattr(f,'filename','(unknown)')} (unreadable)\")\n",
        "    return \" | \".join(parts)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) FastAPI models for JSON endpoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ResultIdPayload(BaseModel):\n",
        "    resultId: int\n",
        "\n",
        "class CopyPayload(BaseModel):\n",
        "    resultId: int\n",
        "\n",
        "class ActionPayload(BaseModel):\n",
        "    action: str  # insurance, emr, transcript, models\n",
        "\n",
        "class StatePayload(BaseModel):\n",
        "    state: str  # can be 'California' or 'CA'\n",
        "    action: Optional[str] = \"select\"\n",
        "\n",
        "class LinkPayload(BaseModel):\n",
        "    resultId: int\n",
        "\n",
        "class NavigationPayload(BaseModel):\n",
        "    page: str\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) Gradio app + API routes\n",
        "\n",
        "We expose all endpoints your React code calls:\n",
        "- `POST /api/search` (multipart)\n",
        "- `POST /api/query` (multipart; same behavior)\n",
        "- `DELETE /api/result`\n",
        "- `POST /api/copy`\n",
        "- `POST /api/action`\n",
        "- `POST /api/state`\n",
        "- `POST /api/link`\n",
        "- `POST /api/navigation` (in spec; safe to have)\n",
        "\n",
        "Also adds CORS so your React app can call the backend."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_gradio_ui():\n",
        "    # For Gradio UI testing, create a mock session store\n",
        "    # (Gradio UI doesn't have request context like API endpoints do)\n",
        "    mock_session = {\n",
        "        \"created_at\": time.time(),\n",
        "        \"prompts\": [],\n",
        "        \"results\": [],\n",
        "        \"copies\": [],\n",
        "        \"deletes\": [],\n",
        "        \"selected_state\": None,\n",
        "        \"model\": \"mock-default\",\n",
        "    }\n",
        "    \n",
        "    class MockStore:\n",
        "        def __init__(self):\n",
        "            self._session = mock_session\n",
        "        def add_prompt(self, p): self._session[\"prompts\"].append(p)\n",
        "        def set_results(self, r): self._session[\"results\"] = r\n",
        "        @property\n",
        "        def data(self): return self._session\n",
        "    \n",
        "    mock_store = MockStore()\n",
        "    \n",
        "    with gr.Blocks(title=\"FindCare Backend (Dev)\") as demo:\n",
        "        gr.Markdown(\"## FindCare Backend (Dev Panel)\\nUse this for quick backend testing while your React UI is wiring up.\")\n",
        "        with gr.Row():\n",
        "            prompt = gr.Textbox(label=\"Prompt\", lines=3, placeholder=\"Find cardiologists in CA who accept Blue Cross\")\n",
        "            files = gr.File(label=\"Files\", file_count=\"multiple\")\n",
        "        out = gr.JSON(label=\"Search response\")\n",
        "        btn = gr.Button(\"Run mock /api/search\")\n",
        "\n",
        "        def _run(prompt_text, uploaded_files):\n",
        "            mock_store.add_prompt(prompt_text or \"\")\n",
        "            results = mock_search(prompt_text or \"\", mock_store.data.get(\"selected_state\"))\n",
        "            mock_store.set_results(results)\n",
        "            return {\"results\": results}\n",
        "\n",
        "        btn.click(_run, inputs=[prompt, files], outputs=[out])\n",
        "\n",
        "        gr.Markdown(\"### Session snapshot\")\n",
        "        sess = gr.JSON()\n",
        "        refresh = gr.Button(\"Refresh session store\")\n",
        "        refresh.click(lambda: mock_store.data, inputs=[], outputs=[sess])\n",
        "    return demo\n",
        "\n",
        "demo = build_gradio_ui()\n",
        "app = demo.app  # FastAPI app\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CORS: allow your React dev server + local variants. Tighten for production.\n",
        "app.add_middleware(\n",
        "    CORSMiddleware,\n",
        "    allow_origins=[\n",
        "        \"http://localhost:5173\",\n",
        "        \"http://127.0.0.1:5173\",\n",
        "        \"http://localhost:3000\",\n",
        "        \"http://127.0.0.1:3000\",\n",
        "    ],\n",
        "    allow_credentials=True,\n",
        "    allow_methods=[\"*\"],\n",
        "    allow_headers=[\"*\"],\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "def _normalize_state(state: str) -> str:\n",
        "    state = (state or \"\").strip()\n",
        "    if not state:\n",
        "        return \"\"\n",
        "    if len(state) == 2 and state.isalpha():\n",
        "        return state.upper()\n",
        "    # map full name to abbr\n",
        "    for name, abbr in STATE_ABBR.items():\n",
        "        if name.lower() == state.lower():\n",
        "            return abbr\n",
        "    return state[:2].upper()\n",
        "\n",
        "@app.post(\"/api/search\")\n",
        "async def api_search(request: Request, prompt: str = Form(...), files: Optional[List[UploadFile]] = File(None)):\n",
        "    store = SessionStore(request)\n",
        "    store.add_prompt(prompt)\n",
        "    file_summary = await summarize_uploads(files)\n",
        "    _ = file_summary  # Can incorporate file_summary into real LLM prompt/context later\n",
        "\n",
        "    results = mock_search(prompt, store.data.get(\"selected_state\"))\n",
        "    store.set_results(results)\n",
        "    \n",
        "    response = JSONResponse({\"results\": results})\n",
        "    store.set_cookie_on_response(response)\n",
        "    return response\n",
        "\n",
        "@app.post(\"/api/query\")\n",
        "async def api_query(request: Request, prompt: str = Form(...), files: Optional[List[UploadFile]] = File(None)):\n",
        "    # Same behavior as /api/search (frontend calls both)\n",
        "    return await api_search(request=request, prompt=prompt, files=files)\n",
        "\n",
        "@app.delete(\"/api/result\")\n",
        "async def api_delete_result(request: Request, payload: ResultIdPayload):\n",
        "    store = SessionStore(request)\n",
        "    store.delete_result(payload.resultId)\n",
        "    response = JSONResponse({\"ok\": True})\n",
        "    store.set_cookie_on_response(response)\n",
        "    return response\n",
        "\n",
        "@app.post(\"/api/copy\")\n",
        "async def api_copy(request: Request, payload: CopyPayload):\n",
        "    store = SessionStore(request)\n",
        "    store.copy_result(payload.resultId)\n",
        "    response = JSONResponse({\"ok\": True})\n",
        "    store.set_cookie_on_response(response)\n",
        "    return response\n",
        "\n",
        "@app.post(\"/api/action\")\n",
        "async def api_action(request: Request, payload: ActionPayload):\n",
        "    store = SessionStore(request)\n",
        "    action = (payload.action or \"\").strip().lower()\n",
        "\n",
        "    if action == \"insurance\":\n",
        "        response = JSONResponse({\"ok\": True, \"url\": \"https://example.com/insurance-portal\"})\n",
        "        store.set_cookie_on_response(response)\n",
        "        return response\n",
        "    if action == \"emr\":\n",
        "        response = JSONResponse({\"ok\": True, \"url\": \"https://example.com/emr-access\"})\n",
        "        store.set_cookie_on_response(response)\n",
        "        return response\n",
        "    if action == \"transcript\":\n",
        "        response = JSONResponse({\n",
        "            \"transcript\": store.transcript_text(),\n",
        "            \"summary\": store.summary_text(),\n",
        "            \"downloadUrl\": None\n",
        "        })\n",
        "        store.set_cookie_on_response(response)\n",
        "        return response\n",
        "    if action == \"models\":\n",
        "        available = [\n",
        "            {\"id\": \"mock-default\", \"name\": \"Mock Default\", \"description\": \"No-cost stub model.\"},\n",
        "            {\"id\": \"openai-gpt\", \"name\": \"OpenAI (future)\", \"description\": \"Placeholder for OpenAI integration.\"},\n",
        "            {\"id\": \"local-llama\", \"name\": \"Local Llama (future)\", \"description\": \"Placeholder for local model.\"},\n",
        "        ]\n",
        "        response = JSONResponse({\"availableModels\": available, \"currentModel\": store.data.get(\"model\")})\n",
        "        store.set_cookie_on_response(response)\n",
        "        return response\n",
        "\n",
        "    response = JSONResponse({\"error\": f\"Unknown action: {payload.action}\", \"code\": \"BAD_ACTION\"}, status_code=400)\n",
        "    store.set_cookie_on_response(response)\n",
        "    return response\n",
        "\n",
        "@app.post(\"/api/state\")\n",
        "async def api_state(request: Request, payload: StatePayload):\n",
        "    store = SessionStore(request)\n",
        "    abbr = _normalize_state(payload.state)\n",
        "    store.set_state(abbr)\n",
        "\n",
        "    # Return a provider list filtered by state, plus minimal state info.\n",
        "    providers = mock_search(\"\", selected_state=abbr)\n",
        "    store.set_results(providers)\n",
        "\n",
        "    response = JSONResponse({\n",
        "        \"providers\": providers,\n",
        "        \"stateInfo\": {\n",
        "            \"name\": abbr,\n",
        "            \"insuranceCoverage\": \"Mock coverage info (replace with real content).\",\n",
        "            \"regulations\": \"Mock regulations info (replace with real content).\"\n",
        "        }\n",
        "    })\n",
        "    store.set_cookie_on_response(response)\n",
        "    return response\n",
        "\n",
        "@app.post(\"/api/link\")\n",
        "async def api_link(request: Request, payload: LinkPayload):\n",
        "    store = SessionStore(request)\n",
        "    rid = payload.resultId\n",
        "    response = JSONResponse({\"url\": f\"https://example.com/provider/{rid}\"})\n",
        "    store.set_cookie_on_response(response)\n",
        "    return response\n",
        "\n",
        "@app.post(\"/api/navigation\")\n",
        "async def api_navigation(request: Request, payload: NavigationPayload):\n",
        "    store = SessionStore(request)\n",
        "    page = (payload.page or \"\").strip().lower()\n",
        "    response = JSONResponse({\"ok\": True, \"page\": page})\n",
        "    store.set_cookie_on_response(response)\n",
        "    return response\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6) Launch\n",
        "\n",
        "- In a notebook: use `prevent_thread_lock=True`.\n",
        "- For React dev: point your frontend dev server proxy to this backend, or run both on localhost and call these endpoints directly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'socket' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     13\u001b[39m                 \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m     14\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# Could not find free port\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m port = \u001b[43mfind_free_port\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m7860\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m port \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     18\u001b[39m     \u001b[38;5;66;03m# Let Gradio auto-select a port\u001b[39;00m\n\u001b[32m     19\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mCould not find free port starting from 7860, letting Gradio auto-select...\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 8\u001b[39m, in \u001b[36mfind_free_port\u001b[39m\u001b[34m(start_port, max_attempts)\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_attempts):\n\u001b[32m      7\u001b[39m     port = start_port + i\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43msocket\u001b[49m.socket(socket.AF_INET, socket.SOCK_STREAM) \u001b[38;5;28;01mas\u001b[39;00m s:\n\u001b[32m      9\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     10\u001b[39m             s.bind((\u001b[33m'\u001b[39m\u001b[33m127.0.0.1\u001b[39m\u001b[33m'\u001b[39m, port))\n",
            "\u001b[31mNameError\u001b[39m: name 'socket' is not defined"
          ]
        }
      ],
      "source": [
        "# Launch Gradio (notebook-friendly)\n",
        "# Try port 7860, if busy use next available port\n",
        "\n",
        "def find_free_port(start_port=7860, max_attempts=10):\n",
        "    \"\"\"Find a free port starting from start_port.\"\"\"\n",
        "    for i in range(max_attempts):\n",
        "        port = start_port + i\n",
        "        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n",
        "            try:\n",
        "                s.bind(('127.0.0.1', port))\n",
        "                return port\n",
        "            except OSError:\n",
        "                continue\n",
        "    return None  # Could not find free port\n",
        "\n",
        "port = find_free_port(7860)\n",
        "if port is None:\n",
        "    # Let Gradio auto-select a port\n",
        "    print(\"Could not find free port starting from 7860, letting Gradio auto-select...\")\n",
        "    demo.queue().launch(\n",
        "        server_name=\"127.0.0.1\",\n",
        "        server_port=None,  # Auto-select port\n",
        "        show_api=False,\n",
        "        prevent_thread_lock=True\n",
        "    )\n",
        "else:\n",
        "    print(f\"Launching Gradio on port {port}...\")\n",
        "    demo.queue().launch(\n",
        "        server_name=\"127.0.0.1\",\n",
        "        server_port=port,\n",
        "        show_api=False,\n",
        "        prevent_thread_lock=True\n",
        "    )\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
